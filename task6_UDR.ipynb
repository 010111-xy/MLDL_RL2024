{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "import gym\n",
    "from env.custom_hopper import *\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import env\n",
    "env = gym.make('CustomHopper-source-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('world', 'torso', 'thigh', 'leg', 'foot')\n"
     ]
    }
   ],
   "source": [
    "#print all body names of the en\n",
    "print(env.sim.model.body_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. world\n",
    "    - serves as a reference frame for the entire simulation. It is the origin point from which all other bodies' positions and orientations are measured\n",
    "    - not a physical object\n",
    "    -  Other bodies are positioned and oriented relative to the 'world' body\n",
    "2. Torso\n",
    "    - serves as the main mass of the robot and contains the core components. The torso is responsible for maintaining the robot's **balance** and overall **stability** during movement.\n",
    "    - NOTE: we do **not** want to randomize the torso mass!\n",
    "3. Thigh\n",
    "     - plays a crucial role in the **locomotion** of the robot.\n",
    "     - The thigh moves to create the primary **force needed for hopping or walking.**\n",
    "     - changing mass impacts: the heavier is the mass, the higher is the force and the energy needed to move\n",
    "4. Leg \n",
    "    - contributes to extending and retracting movements necessary for jumping and landing.\n",
    "    - changing mass impacts: it influences how effectively force is transferred from thigh to foot\n",
    "        - Heavier legs might better absorb impacts but could also slow down rapid movements.\n",
    "5. Foot\n",
    "    - provides stability and traction during locomotion.\n",
    "    - changing mass impacts: how the robot lands on the ground and how it lifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to work on the link masses of the Hopper robot, that is: thigh, leg, foot.  Specifically, we want to design a  uniform distribution over these masses in the source environment. \\\\\n",
    "Keep in mind that the in the source env torso_mass_env = torso_mass -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default mass of the torso:2.534291735288517 \n",
      "default mass of the thigh:3.9269908169872427 \n",
      "default mass of the leg:2.7143360527015816 \n",
      "default mass of the foot :5.0893800988154645\n"
     ]
    }
   ],
   "source": [
    "#Default values for the masses\n",
    "print(f\"default mass of the torso:{env.sim.model.body_mass[1]} \\ndefault mass of the thigh:{env.sim.model.body_mass[2]} \\ndefault mass of the leg:{env.sim.model.body_mass[3]} \\ndefault mass of the foot :{env.sim.model.body_mass[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to use this configuration:\n",
    "- we keep the default value for the torso's mass in the target env\n",
    "- set the length of the mass interval on\n",
    "    - 1 kg for  thigh and leg\n",
    "    - 0.5 kg for the foot\n",
    "        - reasoning: a light foot provides more agility, but we do not want the weight to vary drastically for the sake of stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mass bounds for randomization\n",
    "mass_bounds = {\n",
    "    'thigh': {'low': 3.5, 'high': 4.5},  \n",
    "    'leg': {'low': 2.25, 'high': 3.25},    \n",
    "    'foot': {'low': 4.75, 'high': 5.25}    \n",
    "}\n",
    "\n",
    "# Define the fixed torso mass relative to the target environment\n",
    "target_torso_mass = env.sim.model.body_mass[1] \n",
    "source_torso_mass = target_torso_mass - 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us customize the source environment by accessing the MuJoCo model directly. \\\\\n",
    "These changes will only affect the execution of that file, since each environment instance in Gym operates independently. Other files or subsequent executions of other files will not be affected by these changes unless they also modify the MuJoCo model themselves.\n",
    "\n",
    "**NOTE**: If you want to persist modifications to the MuJoCo model across multiple executions or instances, you would need to save the modified parameters and apply them when creating new environment instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a custom environment wrapper that randomizes the parameters each time the environment is reset.\n",
    "class CustomHopperEnvWrapper(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(CustomHopperEnvWrapper, self).__init__(env)\n",
    "        self.env = env\n",
    "        #Access the Mujoco model\n",
    "        self.model = env.unwrapped.sim.model\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        # Randomize masses for thigh, leg, and foot\n",
    "        thigh_mass = np.random.uniform(mass_bounds['thigh']['low'], mass_bounds['thigh']['high'])\n",
    "        leg_mass = np.random.uniform(mass_bounds['leg']['low'], mass_bounds['leg']['high'])\n",
    "        foot_mass = np.random.uniform(mass_bounds['foot']['low'], mass_bounds['foot']['high'])\n",
    "\n",
    "        # Set the masses in the environment\n",
    "        model.body_mass[2] = thigh_mass       # Thigh mass\n",
    "        model.body_mass[3] = leg_mass         # Leg mass\n",
    "        model.body_mass[4] = foot_mass        # Foot mass\n",
    "        model.body_mass[1] = source_torso_mass  # Torso mass\n",
    "\n",
    "        return self.env.reset(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward in source environment: 1336.2054027 +/- 110.34116059635124\n"
     ]
    }
   ],
   "source": [
    "# Create the source environment with the wrapper\n",
    "source_env = gym.make('CustomHopper-source-v0')\n",
    "wrapped_source_env = CustomHopperEnvWrapper(source_env)\n",
    "source_vec_env = make_vec_env(lambda: wrapped_source_env, n_envs=4, monitor_dir=\"./logs/\")\n",
    "\n",
    "# Create the PPO model\n",
    "model = PPO(\"MlpPolicy\", source_vec_env, verbose=0)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=1000000)\n",
    "\n",
    "# Evaluate the policy in the source environment\n",
    "mean_reward, std_reward = evaluate_policy(model, source_vec_env, n_eval_episodes=10)\n",
    "print(f\"Mean reward in source environment: {mean_reward} +/- {std_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "model.save(\"task6_trained_model.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/federica/anaconda3/envs/mldl/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:71: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward on source environment: 1374.1071713209153 +/- 152.4798868139296\n",
      "Mean reward on target environment: 938.6095947742463 +/- 6.220978588408309\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "trained_model = PPO.load(\"task6_trained_model.zip\")\n",
    "\n",
    "# Create environments for source and target environments\n",
    "source_env = gym.make('CustomHopper-source-v0')\n",
    "target_env = gym.make('CustomHopper-target-v0')\n",
    "\n",
    "# Evaluate the trained policy on the source environment\n",
    "mean_reward_source, std_reward_source = evaluate_policy(trained_model, source_env, n_eval_episodes=10)\n",
    "print(f\"Mean reward on source environment: {mean_reward_source} +/- {std_reward_source}\")\n",
    "\n",
    "# Evaluate the trained policy on the target environment\n",
    "mean_reward_target, std_reward_target = evaluate_policy(trained_model, target_env, n_eval_episodes=10)\n",
    "print(f\"Mean reward on target environment: {mean_reward_target} +/- {std_reward_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
